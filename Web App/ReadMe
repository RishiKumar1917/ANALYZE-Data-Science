# Iris Flower Classification

## Overview
This project is a Machine Learning-based web application that classifies Iris flowers into three species: **Setosa, Versicolor, and Virginica** using **Random Forest Classifier**. The model is deployed using **Streamlit**, and it provides a simple interface for users to input flower measurements and get predictions.

## Features
- ğŸŒ¸ **Iris Flower Classification** using **RandomForestClassifier**
- ğŸ“Š **Interactive Web Interface** built with **Streamlit**
- ğŸ **Machine Learning Model** trained on the classic **Iris Dataset**
- ğŸ³ **Docker Support** for easy deployment
- ğŸ” **SHAP Analysis** for Model Explainability
- ğŸš€ **CI/CD Pipeline** using **GitHub Actions**

## Installation & Setup
### 1. Clone the Repository
```sh
git clone https://github.com/yourusername/Iris_Flower_Classification.git
cd Iris_Flower_Classification
```

### 2. Install Dependencies
```sh
pip install -r requirements.txt
```

### 3. Run the Web App
```sh
streamlit run app.py
```

## Docker Deployment
Build and run the container:
```sh
docker build -t iris-classifier .
docker run -p 8501:8501 iris-classifier
```

## Project Structure
```
ğŸ“‚ Iris_Flower_Classification
â”œâ”€â”€ app.py                 # Streamlit Web App
â”œâ”€â”€ iris_model.pkl         # Trained ML Model
â”œâ”€â”€ Dockerfile             # Docker Configuration
â”œâ”€â”€ requirements.txt       # Python Dependencies
â”œâ”€â”€ test_model.py          # Unit Testing using pytest
â”œâ”€â”€ .github/workflows/     # CI/CD Pipeline for Automation
â””â”€â”€ README.md              # Documentation
```

## Model Training
The **Iris dataset** from `sklearn.datasets` is used to train a **Random Forest Classifier**. The model is saved using `joblib` and used for predictions.

## Unit Testing
Run the test suite using **pytest**:
```sh
pytest test_model.py
```

## CI/CD Pipeline
GitHub Actions automatically tests and validates every new push. The workflow file is located in `.github/workflows/python-app.yml`.

## Model Explainability (SHAP)
SHAP (SHapley Additive exPlanations) is used to analyze feature importance and model predictions.

```python
import shap
explainer = shap.Explainer(model)
shap_values = explainer(X_test)
shap.summary_plot(shap_values, X_test)
```

## Contributing
Pull requests are welcome! If you'd like to improve this project, feel free to fork the repo and submit a PR.

## License
MIT License. See `LICENSE` for details.


